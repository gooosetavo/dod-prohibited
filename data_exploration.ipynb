{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce86b4df",
   "metadata": {},
   "source": [
    "# DOD Prohibited Substances Database Analysis\n",
    "\n",
    "This notebook provides tools to load and analyze the DOD prohibited substances database. We'll explore the data structure, perform basic analysis, and create visualizations to understand the substance database better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c5c2a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, let's import all the necessary libraries for data manipulation, analysis, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae646d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries for data manipulation and analysis\n",
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278a93d",
   "metadata": {},
   "source": [
    "## 2. Load the Substance Database\n",
    "\n",
    "Let's load the substance database from the available data sources. We'll try multiple approaches to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9111dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the substance database from JSON file\n",
    "def load_substance_database():\n",
    "    \"\"\"Load the substance database from available sources.\"\"\"\n",
    "    \n",
    "    # Try loading from docs/data.json first\n",
    "    json_path = \"docs/data.json\"\n",
    "    if os.path.exists(json_path):\n",
    "        print(f\"Loading data from {json_path}...\")\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(f\"✓ Successfully loaded {len(df)} substances from JSON file\")\n",
    "        return df\n",
    "    \n",
    "    # Try loading from SQLite database if exists\n",
    "    db_path = \"substances.db\"\n",
    "    if os.path.exists(db_path):\n",
    "        print(f\"Loading data from {db_path}...\")\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df = pd.read_sql_query(\"SELECT * FROM substances\", conn)\n",
    "        conn.close()\n",
    "        print(f\"✓ Successfully loaded {len(df)} substances from SQLite database\")\n",
    "        return df\n",
    "    \n",
    "    # Try using the SubstanceDatabase class from generate_docs.py\n",
    "    try:\n",
    "        from generate_docs import SubstanceDatabase, Settings\n",
    "        print(\"Loading data using SubstanceDatabase class...\")\n",
    "        settings = Settings()\n",
    "        db = SubstanceDatabase(settings.db_file)\n",
    "        # This will create the database if it doesn't exist\n",
    "        print(f\"✓ Database initialized at {settings.db_file}\")\n",
    "        return None  # Return None to indicate database exists but may be empty\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ Could not import database classes: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the database\n",
    "df = load_substance_database()\n",
    "if df is not None:\n",
    "    print(f\"\\nDataset shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "else:\n",
    "    print(\"No data loaded - database may need to be populated first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a7aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DISPLAY_NAME\"] = df[\"Name\"].str.upper()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3872c74-472a-46ea-949f-edc8772bfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from unii_client import UniiDataClient\n",
    "client = UniiDataClient()\n",
    "# client.get_data_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e936e7-f138-44d6-b523-695c347c6294",
   "metadata": {},
   "outputs": [],
   "source": [
    "unii_df = client.load_csv_data('UNII_Records_18Aug2025.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd92fad-e3e8-49d0-b164-6db8eeb67c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unii_df.merge(df, left_on='DISPLAY_NAME', right_on='DISPLAY_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298a2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_substance_data(df):\n",
    "    \"\"\"Clean and preprocess the substance data.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"No data to clean\")\n",
    "        return None\n",
    "    \n",
    "    print(\"=== DATA CLEANING ===\")\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # Create a copy to work with\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Standardize column names (find main name column)\n",
    "    name_column = None\n",
    "    for col in ['Name', 'name', 'substance_name']:\n",
    "        if col in df_clean.columns:\n",
    "            name_column = col\n",
    "            break\n",
    "    \n",
    "    if name_column and name_column != 'name':\n",
    "        df_clean['name'] = df_clean[name_column]\n",
    "        print(f\"✓ Standardized name column from '{name_column}' to 'name'\")\n",
    "    \n",
    "    # Parse JSON fields\n",
    "    json_fields = ['other_names', 'classifications', 'Reasons', 'References']\n",
    "    for field in json_fields:\n",
    "        if field in df_clean.columns:\n",
    "            try:\n",
    "                # Parse JSON strings into actual lists/dicts\n",
    "                df_clean[field + '_parsed'] = df_clean[field].apply(\n",
    "                    lambda x: json.loads(x) if isinstance(x, str) and x.strip().startswith(('[', '{')) else x\n",
    "                )\n",
    "                print(f\"✓ Parsed JSON field: {field}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Could not parse {field}: {e}\")\n",
    "    \n",
    "    # Clean text fields\n",
    "    text_fields = ['name', 'Reason', 'reason', 'searchable_name', 'Searchable_name']\n",
    "    for field in text_fields:\n",
    "        if field in df_clean.columns:\n",
    "            # Remove extra whitespace and handle nulls\n",
    "            df_clean[field] = df_clean[field].astype(str).str.strip()\n",
    "            df_clean[field] = df_clean[field].replace(['nan', 'None', ''], None)\n",
    "    \n",
    "    # Extract simplified reason categories\n",
    "    reason_col = 'Reason' if 'Reason' in df_clean.columns else 'reason'\n",
    "    if reason_col in df_clean.columns:\n",
    "        df_clean['reason_category'] = df_clean[reason_col].apply(extract_reason_category)\n",
    "        print(\"✓ Extracted reason categories\")\n",
    "    \n",
    "    print(f\"✓ Cleaning complete. Shape: {original_shape} → {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "def extract_reason_category(reason_text):\n",
    "    \"\"\"Extract main category from reason text.\"\"\"\n",
    "    if not reason_text or pd.isna(reason_text):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    reason_lower = str(reason_text).lower()\n",
    "    \n",
    "    if 'schedule i' in reason_lower or 'schedule 1' in reason_lower:\n",
    "        return 'Schedule I'\n",
    "    elif 'schedule ii' in reason_lower or 'schedule 2' in reason_lower:\n",
    "        return 'Schedule II'\n",
    "    elif 'schedule iii' in reason_lower or 'schedule 3' in reason_lower:\n",
    "        return 'Schedule III'\n",
    "    elif 'wada' in reason_lower:\n",
    "        return 'WADA Prohibited'\n",
    "    elif 'dodi' in reason_lower:\n",
    "        return 'DoD Policy'\n",
    "    elif 'unapproved' in reason_lower:\n",
    "        return 'Unapproved Drug'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Clean the data\n",
    "if df is not None:\n",
    "    df_clean = clean_substance_data(df)\n",
    "else:\n",
    "    print(\"No data loaded to clean. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52037181",
   "metadata": {},
   "source": [
    "## 5. Basic Data Analysis\n",
    "\n",
    "Let's perform some basic exploratory data analysis to understand the substance database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic analysis of the substance database\n",
    "if 'df_clean' in globals() and df_clean is not None:\n",
    "    print(\"=== BASIC STATISTICS ===\")\n",
    "    print(f\"Total substances: {len(df_clean):,}\")\n",
    "    \n",
    "    # Analyze reason categories\n",
    "    if 'reason_category' in df_clean.columns:\n",
    "        print(\"\\n=== PROHIBITION CATEGORIES ===\")\n",
    "        reason_counts = df_clean['reason_category'].value_counts()\n",
    "        for category, count in reason_counts.items():\n",
    "            percentage = (count / len(df_clean)) * 100\n",
    "            print(f\"{category:<20}: {count:>5} substances ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Create a simple visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        reason_counts.plot(kind='bar', color='steelblue', alpha=0.7)\n",
    "        plt.title('Distribution of Substances by Prohibition Category')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Number of Substances')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Analyze missing data patterns\n",
    "    print(\"\\n=== MISSING DATA ANALYSIS ===\")\n",
    "    missing_data = df_clean.isnull().sum()\n",
    "    missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "    \n",
    "    if len(missing_data) > 0:\n",
    "        print(\"Fields with missing data:\")\n",
    "        for field, count in missing_data.head(10).items():\n",
    "            percentage = (count / len(df_clean)) * 100\n",
    "            print(f\"{field:<25}: {count:>5} missing ({percentage:5.1f}%)\")\n",
    "    else:\n",
    "        print(\"No missing data found!\")\n",
    "    \n",
    "    # Sample some interesting substances\n",
    "    print(\"\\n=== SAMPLE SUBSTANCES ===\")\n",
    "    if 'name' in df_clean.columns:\n",
    "        sample_substances = df_clean['name'].dropna().sample(min(5, len(df_clean))).tolist()\n",
    "        for i, substance in enumerate(sample_substances, 1):\n",
    "            print(f\"{i}. {substance}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No cleaned data available. Please run the data cleaning cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f01226",
   "metadata": {},
   "source": [
    "## 6. Filter and Search Substances\n",
    "\n",
    "Let's create some useful functions to filter and search through the substance database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the existing classes to work with substance data\n",
    "def search_substances_by_name(df, search_term, limit=10):\n",
    "    \"\"\"Search for substances by name.\"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    name_col = 'Name' if 'Name' in df.columns else 'name'\n",
    "    if name_col not in df.columns:\n",
    "        print(\"No name column found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Case-insensitive search\n",
    "    mask = df[name_col].str.contains(search_term, case=False, na=False)\n",
    "    results = df[mask].head(limit)\n",
    "    \n",
    "    print(f\"Found {len(results)} substances matching '{search_term}':\")\n",
    "    return results\n",
    "\n",
    "def filter_by_category(df, category):\n",
    "    \"\"\"Filter substances by prohibition category.\"\"\"\n",
    "    if df is None or 'reason_category' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    filtered = df[df['reason_category'] == category]\n",
    "    print(f\"Found {len(filtered)} substances in category '{category}'\")\n",
    "    return filtered\n",
    "\n",
    "def get_substance_details(df, substance_name):\n",
    "    \"\"\"Get detailed information about a specific substance.\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    name_col = 'Name' if 'Name' in df.columns else 'name'\n",
    "    substance = df[df[name_col].str.contains(substance_name, case=False, na=False)]\n",
    "    \n",
    "    if substance.empty:\n",
    "        print(f\"No substance found matching '{substance_name}'\")\n",
    "        return None\n",
    "    \n",
    "    if len(substance) > 1:\n",
    "        print(f\"Multiple substances found matching '{substance_name}':\")\n",
    "        print(substance[name_col].tolist())\n",
    "        return substance\n",
    "    \n",
    "    return substance.iloc[0]\n",
    "\n",
    "# Example usage with the loaded data\n",
    "if 'df_clean' in globals() and df_clean is not None:\n",
    "    # Search for testosterone-related substances\n",
    "    print(\"=== SEARCH EXAMPLE: Testosterone ===\")\n",
    "    testosterone_results = search_substances_by_name(df_clean, \"testosterone\", limit=5)\n",
    "    if not testosterone_results.empty:\n",
    "        name_col = 'Name' if 'Name' in testosterone_results.columns else 'name'\n",
    "        for idx, row in testosterone_results.iterrows():\n",
    "            print(f\"- {row[name_col]}\")\n",
    "    \n",
    "    # Filter by Schedule I substances\n",
    "    print(\"\\n=== FILTER EXAMPLE: Schedule I ===\")\n",
    "    schedule_i = filter_by_category(df_clean, \"Schedule I\")\n",
    "    if not schedule_i.empty:\n",
    "        print(\"Sample Schedule I substances:\")\n",
    "        name_col = 'Name' if 'Name' in schedule_i.columns else 'name'\n",
    "        for substance in schedule_i[name_col].head(3):\n",
    "            print(f\"- {substance}\")\n",
    "else:\n",
    "    print(\"No data available for search examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5410f82c",
   "metadata": {},
   "source": [
    "## 7. Using the Substance and SubstanceDatabase Classes\n",
    "\n",
    "Let's use the existing classes we've already written to work with the database more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd960e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and use the existing classes\n",
    "try:\n",
    "    from generate_docs import Substance, SubstanceDatabase, Settings\n",
    "    from changelog import ChangeType, SubstanceChange, DateChanges\n",
    "    \n",
    "    print(\"✓ Successfully imported existing classes!\")\n",
    "    \n",
    "    # Initialize the database using our existing infrastructure\n",
    "    settings = Settings()\n",
    "    db = SubstanceDatabase(settings.db_file)\n",
    "    \n",
    "    print(f\"✓ Connected to database: {settings.db_file}\")\n",
    "    \n",
    "    # Get substances using the database class\n",
    "    def get_substances_from_db():\n",
    "        \"\"\"Get all substances from the database using our SubstanceDatabase class.\"\"\"\n",
    "        try:\n",
    "            substances = db.get_all_substances()\n",
    "            print(f\"✓ Retrieved {len(substances)} substances from database\")\n",
    "            return substances\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error retrieving substances: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def analyze_substance_object(substance: Substance):\n",
    "        \"\"\"Analyze a single Substance object.\"\"\"\n",
    "        print(\"\\n=== SUBSTANCE ANALYSIS ===\")\n",
    "        print(f\"Name: {substance.name}\")\n",
    "        print(f\"Key: {substance.key}\")\n",
    "        print(f\"Added: {substance.added_date}\")\n",
    "        print(f\"Updated: {substance.updated_date}\")\n",
    "        \n",
    "        # Get reason information\n",
    "        reason = substance.data.get('Reason') or substance.data.get('reason', 'Not specified')\n",
    "        print(f\"Reason: {reason}\")\n",
    "        \n",
    "        # Get other names if available\n",
    "        other_names = substance.data.get('other_names')\n",
    "        if other_names:\n",
    "            try:\n",
    "                import ast\n",
    "                names_list = ast.literal_eval(other_names) if isinstance(other_names, str) else other_names\n",
    "                if names_list:\n",
    "                    print(f\"Other names: {', '.join(names_list[:3])}{'...' if len(names_list) > 3 else ''}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return substance\n",
    "    \n",
    "    def compare_substances_demo(substances_list):\n",
    "        \"\"\"Demonstrate substance comparison functionality.\"\"\"\n",
    "        if len(substances_list) < 2:\n",
    "            print(\"Need at least 2 substances for comparison demo\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n=== SUBSTANCE COMPARISON DEMO ===\")\n",
    "        substance1 = substances_list[0]\n",
    "        substance2 = substances_list[1]\n",
    "        \n",
    "        # Compare the substances\n",
    "        changed_fields = substance1.compare_with(substance2)\n",
    "        \n",
    "        print(f\"Comparing '{substance1.name}' with '{substance2.name}'\")\n",
    "        print(f\"Changed fields: {changed_fields if changed_fields else 'None'}\")\n",
    "        \n",
    "        return changed_fields\n",
    "    \n",
    "    # Get substances from database\n",
    "    substances = get_substances_from_db()\n",
    "    \n",
    "    if substances:\n",
    "        print(\"\\n=== SAMPLE SUBSTANCE ANALYSIS ===\")\n",
    "        # Analyze first few substances\n",
    "        for i, substance in enumerate(substances[:3], 1):\n",
    "            print(f\"\\n--- Substance {i} ---\")\n",
    "            analyze_substance_object(substance)\n",
    "        \n",
    "        # Demo comparison\n",
    "        if len(substances) >= 2:\n",
    "            compare_substances_demo(substances)\n",
    "    else:\n",
    "        print(\"No substances found in database. You may need to run generate_docs.py first.\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"⚠ Could not import classes: {e}\")\n",
    "    print(\"Make sure you're running this from the project directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e529813",
   "metadata": {},
   "source": [
    "## 8. Advanced Analysis with Substance Objects\n",
    "\n",
    "Let's perform more advanced analysis using our Substance dataclass methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced analysis using Substance methods\n",
    "def analyze_substance_timestamps(substances_list):\n",
    "    \"\"\"Analyze substance timestamps and modification patterns.\"\"\"\n",
    "    if not substances_list:\n",
    "        return\n",
    "    \n",
    "    print(\"=== TIMESTAMP ANALYSIS ===\")\n",
    "    \n",
    "    # Get timestamps for all substances\n",
    "    timestamps = []\n",
    "    for substance in substances_list:\n",
    "        try:\n",
    "            timestamp = substance.get_last_modified_timestamp()\n",
    "            if timestamp > 0:\n",
    "                timestamps.append(timestamp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if timestamps:\n",
    "        timestamps.sort()\n",
    "        from datetime import datetime\n",
    "        \n",
    "        print(f\"Substances with timestamps: {len(timestamps)}\")\n",
    "        print(f\"Earliest modification: {datetime.fromtimestamp(min(timestamps))}\")\n",
    "        print(f\"Latest modification: {datetime.fromtimestamp(max(timestamps))}\")\n",
    "        \n",
    "        # Show modification frequency by year\n",
    "        years = [datetime.fromtimestamp(ts).year for ts in timestamps]\n",
    "        year_counts = pd.Series(years).value_counts().sort_index()\n",
    "        \n",
    "        print(\"\\nModifications by year:\")\n",
    "        for year, count in year_counts.items():\n",
    "            print(f\"  {year}: {count} substances\")\n",
    "    else:\n",
    "        print(\"No timestamp data available\")\n",
    "\n",
    "def find_recently_modified_substances(substances_list, days_ago=30):\n",
    "    \"\"\"Find substances modified within the last N days.\"\"\"\n",
    "    if not substances_list:\n",
    "        return []\n",
    "    \n",
    "    from datetime import timedelta\n",
    "    threshold_timestamp = int((datetime.now() - timedelta(days=days_ago)).timestamp())\n",
    "    \n",
    "    recent_substances = []\n",
    "    for substance in substances_list:\n",
    "        if substance.was_modified_since(threshold_timestamp):\n",
    "            recent_substances.append(substance)\n",
    "    \n",
    "    print(f\"=== RECENTLY MODIFIED SUBSTANCES (last {days_ago} days) ===\")\n",
    "    print(f\"Found {len(recent_substances)} recently modified substances\")\n",
    "    \n",
    "    for substance in recent_substances[:10]:  # Show first 10\n",
    "        mod_time = datetime.fromtimestamp(substance.get_last_modified_timestamp())\n",
    "        print(f\"- {substance.name} (modified: {mod_time.strftime('%Y-%m-%d')})\")\n",
    "    \n",
    "    return recent_substances\n",
    "\n",
    "def analyze_substance_sources(substances_list):\n",
    "    \"\"\"Analyze source dates and data sources.\"\"\"\n",
    "    print(\"=== SOURCE ANALYSIS ===\")\n",
    "    \n",
    "    source_dates = []\n",
    "    for substance in substances_list:\n",
    "        source_date = substance.get_source_date()\n",
    "        if source_date:\n",
    "            source_dates.append(source_date)\n",
    "    \n",
    "    if source_dates:\n",
    "        print(f\"Substances with source dates: {len(source_dates)}\")\n",
    "        unique_dates = sorted(set(source_dates))\n",
    "        print(f\"Unique source dates: {len(unique_dates)}\")\n",
    "        \n",
    "        if len(unique_dates) <= 10:\n",
    "            print(\"Source dates:\")\n",
    "            for date in unique_dates:\n",
    "                count = source_dates.count(date)\n",
    "                print(f\"  {date}: {count} substances\")\n",
    "        else:\n",
    "            print(f\"Date range: {unique_dates[0]} to {unique_dates[-1]}\")\n",
    "    else:\n",
    "        print(\"No source date information available\")\n",
    "\n",
    "# Run advanced analysis if we have substances\n",
    "if 'substances' in globals() and substances:\n",
    "    analyze_substance_timestamps(substances)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    recent = find_recently_modified_substances(substances, days_ago=90)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    analyze_substance_sources(substances)\n",
    "else:\n",
    "    print(\"No substances available for advanced analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d465570",
   "metadata": {},
   "source": [
    "## 9. Working with Changelog Data\n",
    "\n",
    "Let's explore the changelog functionality using our existing changelog classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9558282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with changelog data using our existing classes\n",
    "def demonstrate_changelog_functionality():\n",
    "    \"\"\"Demonstrate how to work with changelog data.\"\"\"\n",
    "    try:\n",
    "        from changelog import parse_existing_changelog_entries, ChangeType\n",
    "        \n",
    "        print(\"=== CHANGELOG FUNCTIONALITY DEMO ===\")\n",
    "        \n",
    "        # Check if changelog file exists\n",
    "        changelog_path = \"docs/changelog.md\"\n",
    "        if os.path.exists(changelog_path):\n",
    "            print(f\"✓ Found changelog file: {changelog_path}\")\n",
    "            \n",
    "            # Parse existing changelog entries\n",
    "            parsed_changes = parse_existing_changelog_entries(changelog_path)\n",
    "            \n",
    "            print(f\"✓ Parsed {len(parsed_changes.dates)} dates from changelog\")\n",
    "            \n",
    "            # Analyze changelog data\n",
    "            total_changes = 0\n",
    "            change_type_counts = {change_type: 0 for change_type in ChangeType}\n",
    "            \n",
    "            for date_str, date_changes in parsed_changes.dates.items():\n",
    "                date_total = len(date_changes.added) + len(date_changes.modified) + len(date_changes.removed)\n",
    "                total_changes += date_total\n",
    "                \n",
    "                change_type_counts[ChangeType.ADDED] += len(date_changes.added)\n",
    "                change_type_counts[ChangeType.MODIFIED] += len(date_changes.modified)\n",
    "                change_type_counts[ChangeType.REMOVED] += len(date_changes.removed)\n",
    "            \n",
    "            print(\"\\n=== CHANGELOG STATISTICS ===\")\n",
    "            print(f\"Total changes recorded: {total_changes}\")\n",
    "            print(f\"Added substances: {change_type_counts[ChangeType.ADDED]}\")\n",
    "            print(f\"Modified substances: {change_type_counts[ChangeType.MODIFIED]}\")\n",
    "            print(f\"Removed substances: {change_type_counts[ChangeType.REMOVED]}\")\n",
    "            \n",
    "            # Show recent dates\n",
    "            recent_dates = sorted(parsed_changes.dates.keys())[-5:]\n",
    "            print(\"\\nMost recent changelog dates:\")\n",
    "            for date in recent_dates:\n",
    "                changes = parsed_changes.dates[date]\n",
    "                total = len(changes.added) + len(changes.modified) + len(changes.removed)\n",
    "                print(f\"  {date}: {total} changes\")\n",
    "                \n",
    "            return parsed_changes\n",
    "        else:\n",
    "            print(f\"⚠ Changelog file not found: {changelog_path}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error working with changelog: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_sample_substance_change():\n",
    "    \"\"\"Create a sample SubstanceChange for demonstration.\"\"\"\n",
    "    try:\n",
    "        sample_change = SubstanceChange(\n",
    "            change_type=ChangeType.MODIFIED,\n",
    "            substance_name=\"Sample Substance\",\n",
    "            changed_fields=[\"Reason\", \"Classifications\"],\n",
    "            details=\"Updated classification and reason\"\n",
    "        )\n",
    "        \n",
    "        print(\"=== SAMPLE SUBSTANCE CHANGE ===\")\n",
    "        print(f\"Type: {sample_change.change_type.value}\")\n",
    "        print(f\"Substance: {sample_change.substance_name}\")\n",
    "        print(f\"Changed fields: {sample_change.changed_fields}\")\n",
    "        print(f\"Details: {sample_change.details}\")\n",
    "        \n",
    "        return sample_change\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error creating sample change: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run changelog analysis\n",
    "changelog_data = demonstrate_changelog_functionality()\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "sample_change = create_sample_substance_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ab877",
   "metadata": {},
   "source": [
    "## 10. Create Custom Analysis Functions\n",
    "\n",
    "Let's create some custom analysis functions that leverage all our existing infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis functions using our existing infrastructure\n",
    "class SubstanceAnalyzer:\n",
    "    \"\"\"A helper class for analyzing substances using our existing infrastructure.\"\"\"\n",
    "    \n",
    "    def __init__(self, db_file=\"substances.db\"):\n",
    "        \"\"\"Initialize the analyzer with a database connection.\"\"\"\n",
    "        try:\n",
    "            from generate_docs import SubstanceDatabase, Settings\n",
    "            self.settings = Settings()\n",
    "            self.db = SubstanceDatabase(db_file)\n",
    "            self.substances = []\n",
    "            print(f\"✓ Initialized SubstanceAnalyzer with {db_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error initializing analyzer: {e}\")\n",
    "            self.db = None\n",
    "    \n",
    "    def load_substances(self):\n",
    "        \"\"\"Load all substances from the database.\"\"\"\n",
    "        if not self.db:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            self.substances = self.db.get_all_substances()\n",
    "            print(f\"✓ Loaded {len(self.substances)} substances\")\n",
    "            return self.substances\n",
    "        except Exception as e:\n",
    "            print(f\"⚠ Error loading substances: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def search_by_criteria(self, name_contains=None, reason_contains=None, limit=10):\n",
    "        \"\"\"Search substances by various criteria.\"\"\"\n",
    "        if not self.substances:\n",
    "            self.load_substances()\n",
    "        \n",
    "        results = []\n",
    "        for substance in self.substances:\n",
    "            match = True\n",
    "            \n",
    "            if name_contains:\n",
    "                if not substance.name or name_contains.lower() not in substance.name.lower():\n",
    "                    match = False\n",
    "            \n",
    "            if reason_contains and match:\n",
    "                reason = substance.data.get('Reason', '') or substance.data.get('reason', '')\n",
    "                if reason_contains.lower() not in str(reason).lower():\n",
    "                    match = False\n",
    "            \n",
    "            if match:\n",
    "                results.append(substance)\n",
    "                if len(results) >= limit:\n",
    "                    break\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_field_usage(self, field_name):\n",
    "        \"\"\"Analyze how a specific field is used across substances.\"\"\"\n",
    "        if not self.substances:\n",
    "            self.load_substances()\n",
    "        \n",
    "        field_values = []\n",
    "        empty_count = 0\n",
    "        \n",
    "        for substance in self.substances:\n",
    "            value = substance.data.get(field_name)\n",
    "            if value and str(value).strip() and str(value) not in ['null', 'None']:\n",
    "                field_values.append(str(value))\n",
    "            else:\n",
    "                empty_count += 1\n",
    "        \n",
    "        print(f\"=== FIELD ANALYSIS: {field_name} ===\")\n",
    "        print(f\"Total substances: {len(self.substances)}\")\n",
    "        print(f\"Field populated: {len(field_values)} ({len(field_values)/len(self.substances)*100:.1f}%)\")\n",
    "        print(f\"Field empty: {empty_count} ({empty_count/len(self.substances)*100:.1f}%)\")\n",
    "        \n",
    "        if field_values:\n",
    "            unique_values = len(set(field_values))\n",
    "            print(f\"Unique values: {unique_values}\")\n",
    "            \n",
    "            # Show sample values\n",
    "            sample_values = list(set(field_values))[:5]\n",
    "            print(f\"Sample values: {sample_values}\")\n",
    "        \n",
    "        return field_values\n",
    "    \n",
    "    def compare_two_substances(self, name1, name2):\n",
    "        \"\"\"Compare two substances by name.\"\"\"\n",
    "        substance1 = self.find_by_name(name1)\n",
    "        substance2 = self.find_by_name(name2)\n",
    "        \n",
    "        if not substance1 or not substance2:\n",
    "            print(\"One or both substances not found\")\n",
    "            return None\n",
    "        \n",
    "        changed_fields = substance1.compare_with(substance2)\n",
    "        \n",
    "        print(f\"=== COMPARISON: {substance1.name} vs {substance2.name} ===\")\n",
    "        if changed_fields:\n",
    "            print(f\"Different fields: {changed_fields}\")\n",
    "            for field in changed_fields:\n",
    "                val1 = substance1.data.get(field, 'Not set')\n",
    "                val2 = substance2.data.get(field, 'Not set')\n",
    "                print(f\"  {field}: '{val1}' vs '{val2}'\")\n",
    "        else:\n",
    "            print(\"No differences found\")\n",
    "        \n",
    "        return changed_fields\n",
    "    \n",
    "    def find_by_name(self, name_search):\n",
    "        \"\"\"Find a substance by partial name match.\"\"\"\n",
    "        for substance in self.substances:\n",
    "            if substance.name and name_search.lower() in substance.name.lower():\n",
    "                return substance\n",
    "        return None\n",
    "\n",
    "# Create and use the analyzer\n",
    "analyzer = SubstanceAnalyzer()\n",
    "substances = analyzer.load_substances()\n",
    "\n",
    "if substances:\n",
    "    print(\"\\n=== CUSTOM ANALYSIS EXAMPLES ===\")\n",
    "    \n",
    "    # Example 1: Search for steroid-related substances\n",
    "    print(\"\\n--- Search Example ---\")\n",
    "    steroid_results = analyzer.search_by_criteria(name_contains=\"steroid\", limit=5)\n",
    "    for substance in steroid_results:\n",
    "        print(f\"- {substance.name}\")\n",
    "    \n",
    "    # Example 2: Analyze label_terms field usage\n",
    "    print(\"\\n--- Field Analysis Example ---\")\n",
    "    analyzer.analyze_field_usage(\"label_terms\")\n",
    "    \n",
    "    # Example 3: Find substances with specific reasons\n",
    "    print(\"\\n--- Reason Filter Example ---\")\n",
    "    wada_results = analyzer.search_by_criteria(reason_contains=\"WADA\", limit=3)\n",
    "    for substance in wada_results:\n",
    "        reason = substance.data.get('Reason', 'Not specified')\n",
    "        print(f\"- {substance.name}: {reason}\")\n",
    "\n",
    "else:\n",
    "    print(\"No substances loaded for custom analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
